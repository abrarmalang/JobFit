# ğŸš€ JobFit v2 â€” AI-Powered Job Recommendation System

JobFit v2 is a complete end-to-end AI system that collects real job postings, cleans & enriches them, generates embeddings, trains a custom KMeans ML model, and serves job recommendations using FastAPI.

This README contains the full setup instructions + diagrams for architecture, data flow, pipelines, and model training.

---

# ğŸ—ï¸ System Architecture (High-Level)

## Data Collection & Processing Pipeline

```mermaid
flowchart LR
    A[Adzuna API] --> C[Collection Scripts]
    B[RemoteOK API] --> C
    C --> D[Raw JSON]
    D --> E[Data Processing]
    E --> F[jobs.parquet]


```

## ML Training & Deployment Pipeline

```mermaid
flowchart LR
    G[jobs.parquet] --> H[Embedding Generator]
    H --> I[Embeddings]
    I --> J[KMeans Trainer]
    J --> K[Trained Model]
    K --> L[FastAPI App]
    L --> M[Job UI]


```

---

# ğŸ”„ End-to-End Pipeline Overview

```mermaid
sequenceDiagram
    autonumber
    participant U as User
    participant API as FastAPI Web App
    participant RE as Recommendation Engine
    participant ML as ML Model (KMeans + Embeddings)

    U->>API: Enter skills, role, location
    API->>RE: Forward request
    RE->>ML: Compute embedding + cluster score
    ML-->>RE: Top job matches
    RE-->>API: Sorted results
    API-->>U: Recommended Jobs
```

---

# ğŸ“¦ 1. Requirements

- Python **3.11**
- Pip + virtualenv
- `.env` file in project root:

```
ADZUNA_APP_ID=your_id
ADZUNA_APP_KEY=your_key
```

---

# ğŸ’» 2. Install Dependencies

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
pip install -r requirements-worker.txt
```

---

# ğŸŒ 3. Run the Web App

```bash
uvicorn webapp.app.main:app --reload
```

Your app runs at:

â¡ http://127.0.0.1:8000  
â¡ http://127.0.0.1:8000/job-search  
â¡ http://127.0.0.1:8000/job-match  
â¡ http://127.0.0.1:8000/mlops.html  

---

# ğŸ› ï¸ 4. Run the Full Pipeline

## ğŸ“¥ Step 1 â€” Collect Jobs

```bash
python scripts/run_collection_adzuna.py
python scripts/run_collection_remoteok.py
```

Produces:

```
data/raw/adzuna/
data/raw/remoteok/
```

---

## ğŸ§¹ Step 2 â€” Process Dataset

```bash
python scripts/run_processing.py
```

Produces:

```
data/processed/jobs.parquet
```

---

## ğŸ§¬ Step 3 â€” Generate Embeddings

```bash
python scripts/run_generate_embeddings.py
```

Outputs:

```
models/embeddings/all-mpnet-base-v2/jobs.npy
models/embeddings/all-mpnet-base-v2/jobs.parquet
```

---

## ğŸ§  Step 4 â€” Train Custom KMeans Model

```bash
python src/workers/model_training/train_cluster_model.py
```

Outputs:

```
models/trained/job_cluster_model_*.pkl
models/trained/job_clusters_*.parquet
```

---

# ğŸ¤– Model Training Workflow Diagram

```mermaid
flowchart LR
    A[Jobs.parquet<br>Cleaned Dataset] --> B[SentenceTransformer<br>MPNet Embedding]
    B --> C[768-Dimensional Vectors]
    C --> D[KMeans Clustering<br>k=20]
    D --> E[Cluster Labels Saved]
    E --> F[Model Saved<br>.pkl + .parquet]

    classDef strong fill:#004466,stroke:#003344,color:#fff;
    class A,B,C,D,E,F strong;
```

---

# ğŸ¨ 5. Visual Analytics Notebook (EDA)

Open:

```
notebook/eda_and_visuals.ipynb
```

It generates PNGs into:

```
notebook/figures/
```

Including:

### ğŸ”¹ Jobs by Country  
### ğŸ”¹ Jobs by Category  
### ğŸ”¹ Jobs by Source  
### ğŸ”¹ Job Age Histogram  
### ğŸ”¹ Missing Data Heatmap  
### ğŸ”¹ PCA Job Embedding Visualization  
### ğŸ”¹ Silhouette Cluster Score  
### ğŸ”¹ Cluster Size Distribution  

---

# ğŸš€ Deployment (Render-Ready)

Render command:

```bash
uvicorn webapp.app.main:app --host 0.0.0.0 --port $PORT
```

Make sure to include folders:

```
models/trained/
models/embeddings/
data/processed/
```

---

# ğŸ“ Project Structure (Tree)

```plaintext
JobFit-main/
â”‚
â”œâ”€â”€ webapp/
â”‚   â””â”€â”€ app/main.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_collection_adzuna.py
â”‚   â”œâ”€â”€ run_collection_remoteok.py
â”‚   â”œâ”€â”€ run_processing.py
â”‚   â””â”€â”€ run_generate_embeddings.py
â”‚
â”œâ”€â”€ src/workers/
â”‚   â””â”€â”€ model_training/train_cluster_model.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/jobs.parquet
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ trained/
â”‚
â””â”€â”€ notebook/
    â”œâ”€â”€ eda_and_visuals.ipynb
    â””â”€â”€ figures/
```

---

# ğŸ§© Quick Troubleshooting

| Problem | Solution |
|--------|----------|
| Embeddings not loading | Re-run embedding generator |
| Model outdated | Re-run training script |
| Missing keys | Add `.env` |
| Memory high | Use `.npy` embeddings (already implemented) |
| Slow semantic search | Ensure model + embeddings preloaded |

